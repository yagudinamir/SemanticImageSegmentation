{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import *\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import time\n",
    "import functools\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "%env CITYSCAPES_DATASET = /path/to/data\n",
    "from tensorflow.metrics import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "EPOCHS_PER_EVAL = 1\n",
    "BATCH_SIZE = 1\n",
    "TOTAL_SIZE = 800\n",
    "VAL_SIZE = 1\n",
    "SCALE_RATE = 2\n",
    "IMG_SHAPE = (int(1024/SCALE_RATE), int(2048/SCALE_RATE), 3)\n",
    "VERBOSE = 1\n",
    "START_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"DeepLab v3 model\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.slim.nets import resnet_v2\n",
    "from tensorflow.contrib import layers as layers_lib\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers\n",
    "from tensorflow.contrib.slim.python.slim.nets import resnet_utils\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "\n",
    "\n",
    "last_ten_acc = []\n",
    "_NUM_CLASSES = 20\n",
    "_HEIGHT = IMG_SHAPE[0]\n",
    "_WIDTH = IMG_SHAPE[1]\n",
    "_DEPTH = IMG_SHAPE[2]\n",
    "_MIN_SCALE = 0.5\n",
    "_MAX_SCALE = 2.0\n",
    "_IGNORE_LABEL = 255\n",
    "\n",
    "_POWER = 0.9\n",
    "_MOMENTUM = 0.9\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9997\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9997\n",
    "_WEIGHT_DECAY = 5e-4\n",
    "\n",
    "\n",
    "def atrous_spatial_pyramid_pooling(inputs, output_stride, batch_norm_decay, is_training, depth=256):\n",
    "\n",
    "  \"\"\"Atrous Spatial Pyramid Pooling.\n",
    "\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, height, width, channels].\n",
    "    output_stride: The ResNet unit's stride. Determines the rates for atrous convolution.\n",
    "      the rates are (6, 12, 18) when the stride is 16, and doubled when 8.\n",
    "    batch_norm_decay: The moving average decay when estimating layer activation\n",
    "      statistics in batch normalization.\n",
    "    is_training: A boolean denoting whether the input is for training.\n",
    "    depth: The depth of the ResNet unit output.\n",
    "\n",
    "  Returns:\n",
    "    The atrous spatial pyramid pooling output.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\"aspp\"):\n",
    "    if output_stride not in [8, 16]:\n",
    "      raise ValueError('output_stride must be either 8 or 16.')\n",
    "\n",
    "    atrous_rates = [6, 12, 18]\n",
    "    if output_stride == 8:\n",
    "      atrous_rates = [2*rate for rate in atrous_rates]\n",
    "\n",
    "    with tf.contrib.slim.arg_scope(resnet_v2.resnet_arg_scope(batch_norm_decay=batch_norm_decay)):\n",
    "      with arg_scope([layers.batch_norm], is_training=is_training):\n",
    "        inputs_size = tf.shape(inputs)[1:3]\n",
    "        # (a) one 1x1 convolution and three 3x3 convolutions with rates = (6, 12, 18) when output stride = 16.\n",
    "        # the rates are doubled when output stride = 8.\n",
    "        conv_1x1 = layers_lib.conv2d(inputs, depth, [1, 1], stride=1, scope=\"conv_1x1\")\n",
    "        conv_3x3_1 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[0], scope='conv_3x3_1')\n",
    "        conv_3x3_2 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[1], scope='conv_3x3_2')\n",
    "        conv_3x3_3 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[2], scope='conv_3x3_3')\n",
    "        tf.summary.image('activations1', tf.reshape(conv_1x1,(256,64,128,1)))\n",
    "        # (b) the image-level features\n",
    "        with tf.variable_scope(\"image_level_features\"):\n",
    "          # global average pooling\n",
    "          image_level_features = tf.reduce_mean(inputs, [1, 2], name='global_average_pooling', keepdims=True)\n",
    "          # 1x1 convolution with 256 filters( and batch normalization)\n",
    "          image_level_features = layers_lib.conv2d(image_level_features, depth, [1, 1], stride=1, scope='conv_1x1')\n",
    "          # bilinearly upsample features\n",
    "          image_level_features = tf.image.resize_bilinear(image_level_features, inputs_size, name='upsample')\n",
    "          tf.summary.image('activations', tf.reshape(image_level_features,(256,64,128,1)))\n",
    "\n",
    "        net = tf.concat([conv_1x1, conv_3x3_1, conv_3x3_2, conv_3x3_3, tf.cast(image_level_features,tf.float32)], axis=3, name='concat')\n",
    "        net = layers_lib.conv2d(net, depth, [1, 1], stride=1, scope='conv_1x1_concat')\n",
    "\n",
    "        return net\n",
    "\n",
    "\n",
    "def deeplab_v3_generator(num_classes,\n",
    "                         output_stride,\n",
    "                         base_architecture,\n",
    "                         pre_trained_model,\n",
    "                         batch_norm_decay,\n",
    "                         data_format='channels_last'):\n",
    "  \n",
    "      \"\"\"Generator for DeepLab v3 model.\n",
    "\n",
    "      Args:\n",
    "        num_classes: The number of possible classes for image classification.\n",
    "        output_stride: The ResNet unit's stride. Determines the rates for atrous convolution.\n",
    "          the rates are (6, 12, 18) when the stride is 16, and doubled when 8.\n",
    "        base_architecture: The architecture of base Resnet building block.\n",
    "        pre_trained_model: The path to the directory that contains pre-trained models.\n",
    "        batch_norm_decay: The moving average decay when estimating layer activation\n",
    "          statistics in batch normalization.\n",
    "        data_format: The input format ('channels_last', 'channels_first', or None).\n",
    "          If set to None, the format is dependent on whether a GPU is available.\n",
    "          Only 'channels_last' is supported currently.\n",
    "\n",
    "      Returns:\n",
    "        The model function that takes in `inputs` and `is_training` and\n",
    "        returns the output tensor of the DeepLab v3 model.\n",
    "      \"\"\"\n",
    "      if data_format is None:\n",
    "        # data_format = (\n",
    "        #     'channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "        pass\n",
    "\n",
    "      if batch_norm_decay is None:\n",
    "        batch_norm_decay = _BATCH_NORM_DECAY\n",
    "\n",
    "      if base_architecture not in ['resnet_v2_50', 'resnet_v2_101']:\n",
    "        raise ValueError(\"'base_architrecture' must be either 'resnet_v2_50' or 'resnet_v2_101'.\")\n",
    "\n",
    "      if base_architecture == 'resnet_v2_50':\n",
    "        base_model = resnet_v2.resnet_v2_50\n",
    "      else:\n",
    "        base_model = resnet_v2.resnet_v2_101\n",
    "\n",
    "      def model(inputs, is_training):\n",
    "        \"\"\"Constructs the ResNet model given the inputs.\"\"\"\n",
    "        if data_format == 'channels_first':\n",
    "          # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n",
    "          # This provides a large performance boost on GPU. See\n",
    "          # https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "          inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "        # tf.logging.info('net shape: {}'.format(inputs.shape))\n",
    "\n",
    "        with tf.contrib.slim.arg_scope(resnet_v2.resnet_arg_scope(batch_norm_decay=batch_norm_decay)):\n",
    "          logits, end_points = base_model(inputs,\n",
    "                                          num_classes=None,\n",
    "                                          is_training=is_training,\n",
    "                                          global_pool=False,\n",
    "                                          output_stride=output_stride)\n",
    "\n",
    "        if is_training:\n",
    "          exclude = [base_architecture + '/logits', 'global_step']\n",
    "          variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "          tf.train.init_from_checkpoint(pre_trained_model,\n",
    "                                        {v.name.split(':')[0]: v for v in variables_to_restore})\n",
    "\n",
    "        inputs_size = tf.shape(inputs)[1:3]\n",
    "        net = end_points[base_architecture + '/block4']\n",
    "        net = atrous_spatial_pyramid_pooling(net, output_stride, batch_norm_decay, is_training)\n",
    "        with tf.variable_scope(\"upsampling_logits\"):\n",
    "          net = layers_lib.conv2d(net, num_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='conv_1x1')\n",
    "          logits = tf.image.resize_bilinear(net, inputs_size, name='upsample')\n",
    "\n",
    "        return logits\n",
    "\n",
    "      return model\n",
    "\n",
    "def deeplabv3_model_fn(features, labels, mode, params):\n",
    "  \n",
    "  images=tf.cast(features,tf.uint8)\n",
    "  network = deeplab_v3_generator(params['num_classes'],\n",
    "                                 params['output_stride'],\n",
    "                                 params['base_architecture'],\n",
    "                                 params['pre_trained_model'],\n",
    "                                 params['batch_norm_decay'])\n",
    "    \n",
    "    \n",
    "  logits = network(features, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  pred_classes = tf.expand_dims(tf.argmax(logits, axis=3, output_type=tf.int32), axis=3)\n",
    "\n",
    "  pred_decoded_labels = tf.py_func(preprocessing.decode_labels,\n",
    "                                   [pred_classes, params['batch_size'], params['num_classes']],\n",
    "                                   tf.uint8)\n",
    "\n",
    "  predictions = {\n",
    "      'classes': pred_classes,\n",
    "      'probabilities': tf.nn.softmax(logits, name='softmax_tensor'),\n",
    "      'decoded_labels': pred_decoded_labels,      \n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Delete 'decoded_labels' from predictions because custom functions produce error when used with saved_model\n",
    "    predictions_without_decoded_labels = predictions.copy()\n",
    "    del predictions_without_decoded_labels['decoded_labels']\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'preds': tf.estimator.export.PredictOutput(\n",
    "                predictions)\n",
    "        })\n",
    "\n",
    "  gt_decoded_labels = tf.py_func(preprocessing.decode_labels,\n",
    "                                 [labels, params['batch_size'], params['num_classes']], tf.uint8)\n",
    "\n",
    "  labels = tf.squeeze(labels, axis=3)  # reduce the channel dimension.\n",
    "\n",
    "  logits_by_num_classes = tf.reshape(logits, [-1, params['num_classes']])\n",
    "  labels_flat = tf.reshape(labels, [-1, ])\n",
    "\n",
    "  valid_indices = tf.to_int32(labels_flat <= params['num_classes'] - 1)\n",
    "  valid_logits = tf.dynamic_partition(logits_by_num_classes, valid_indices, num_partitions=2)[1]\n",
    "  valid_labels = tf.dynamic_partition(labels_flat, valid_indices, num_partitions=2)[1]\n",
    "\n",
    "  preds_flat = tf.reshape(pred_classes, [-1, ])\n",
    "  valid_preds = tf.dynamic_partition(preds_flat, valid_indices, num_partitions=2)[1]\n",
    "  confusion_matrix = tf.confusion_matrix(valid_labels, valid_preds, num_classes=params['num_classes'])\n",
    "\n",
    "  predictions['valid_preds'] = valid_preds\n",
    "  predictions['valid_labels'] = valid_labels\n",
    "  predictions['confusion_matrix'] = confusion_matrix\n",
    "\n",
    "  cross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
    "      logits=valid_logits, labels=tf.cast(valid_labels,tf.int32))\n",
    "  tf.summary.scalar('trainable_params', np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()]))\n",
    "  tf.logging.info(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()]))\n",
    "  # Create a tensor named cross_entropy for logging purposes.\n",
    "  tf.identity(cross_entropy, name='cross_entropy')\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "  \n",
    "  if not params['freeze_batch_norm']:\n",
    "    train_var_list = [v for v in tf.trainable_variables()]\n",
    "  else:\n",
    "    train_var_list = [v for v in tf.trainable_variables()\n",
    "                      if 'beta' not in v.name and 'gamma' not in v.name]\n",
    "\n",
    "  # Add weight decay to the loss.\n",
    "  with tf.variable_scope(\"total_loss\"):\n",
    "    loss = cross_entropy + params.get('weight_decay', _WEIGHT_DECAY) * tf.add_n(\n",
    "        [tf.nn.l2_loss(v) for v in train_var_list])\n",
    "  # loss = tf.losses.get_total_loss()  # obtain the regularization losses as well\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    tf.summary.image('images',\n",
    "                     tf.concat(axis=2, values=[images, gt_decoded_labels, pred_decoded_labels]),\n",
    "                     max_outputs=params['tensorboard_images_max_outputs'])  # Concatenate row-wise.\n",
    "\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    if params['learning_rate_policy'] == 'piecewise':\n",
    "      # Scale the learning rate linearly with the batch size. When the batch size\n",
    "      # is 128, the learning rate should be 0.1.\n",
    "      initial_learning_rate = 0.1 * params['batch_size'] / 128\n",
    "      batches_per_epoch = params['num_train'] / params['batch_size']\n",
    "      # Multiply the learning rate by 0.1 at 100, 150, and 200 epochs.\n",
    "      boundaries = [int(batches_per_epoch * epoch) for epoch in [100, 150, 200]]\n",
    "      values = [initial_learning_rate * decay for decay in [1, 0.1, 0.01, 0.001]]\n",
    "      learning_rate = tf.train.piecewise_constant(\n",
    "          tf.cast(global_step, tf.int16), boundaries, values)\n",
    "    elif params['learning_rate_policy'] == 'poly':\n",
    "      learning_rate = tf.train.polynomial_decay(\n",
    "          params['initial_learning_rate'],\n",
    "          tf.cast(global_step, tf.int16) - params['initial_global_step'],\n",
    "          params['max_iter'], params['end_learning_rate'], power=params['power'])\n",
    "    else:\n",
    "      raise ValueError('Learning rate policy must be \"piecewise\" or \"poly\"')\n",
    "\n",
    "    # Create a tensor named learning_rate for logging purposes\n",
    "    tf.identity(learning_rate, name='learning_rate')\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=params['momentum'])\n",
    "\n",
    "    # Batch norm requires update ops to be added as a dependency to the train_op\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "      train_op = optimizer.minimize(loss, global_step, var_list=train_var_list)\n",
    "  else:\n",
    "    train_op = None\n",
    "  auc = tf.metrics.auc(valid_labels, valid_preds)\n",
    "  tf.identity(auc[0], name='train_auc')\n",
    "  tf.summary.scalar('train_auc', auc[0])\n",
    "  accuracy = tf.metrics.accuracy(\n",
    "      valid_labels, valid_preds)\n",
    "  mean_iou = tf.metrics.mean_iou(valid_labels, valid_preds, params['num_classes'])\n",
    "  metrics = {'px_accuracy': accuracy, 'mean_iou': mean_iou, 'auc' : auc}\n",
    "  tf.get_default_graph().as_graph_def() \n",
    "                \n",
    "  # Create a tensor named train_accuracy for logging purposes\n",
    "  tf.identity(accuracy[1], name='train_px_accuracy')\n",
    "  tf.summary.scalar('train_px_accuracy', accuracy[1])\n",
    "\n",
    "  def compute_mean_iou(total_cm, name='mean_iou'):\n",
    "    \"\"\"Compute the mean intersection-over-union via the confusion matrix.\"\"\"\n",
    "    sum_over_row = tf.to_float(tf.reduce_sum(total_cm, 0))\n",
    "    sum_over_col = tf.to_float(tf.reduce_sum(total_cm, 1))\n",
    "    cm_diag = tf.to_float(tf.diag_part(total_cm))\n",
    "    denominator = sum_over_row + sum_over_col - cm_diag\n",
    "\n",
    "    # The mean is only computed over classes that appear in the\n",
    "    # label or prediction tensor. If the denominator is 0, we need to\n",
    "    # ignore the class.\n",
    "    num_valid_entries = tf.reduce_sum(tf.cast(\n",
    "        tf.not_equal(denominator, 0), dtype=tf.float32))\n",
    "\n",
    "    # If the value of the denominator is 0, set it to 1 to avoid\n",
    "    # zero division.\n",
    "    denominator = tf.where(\n",
    "        tf.greater(denominator, 0),\n",
    "        denominator,\n",
    "        tf.ones_like(denominator))\n",
    "    iou = tf.div(cm_diag, denominator)\n",
    "\n",
    "    for i in range(params['num_classes']):\n",
    "      tf.identity(iou[i], name='train_iou_class{}'.format(i))\n",
    "      tf.summary.scalar('train_iou_class{}'.format(i), iou[i])\n",
    "\n",
    "    # If the number of valid entries is 0 (no classes) we return 0.\n",
    "    result = tf.where(\n",
    "        tf.greater(num_valid_entries, 0),\n",
    "        tf.reduce_sum(iou, name=name) /num_valid_entries,\n",
    "        0)\n",
    "    return result\n",
    "\n",
    "  train_mean_iou = compute_mean_iou(mean_iou[1])\n",
    "\n",
    "  tf.identity(train_mean_iou, name='train_mean_iou')\n",
    "  tf.summary.scalar('train_mean_iou', train_mean_iou)\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "eval_metric_ops=metrics)\n",
    "\n",
    "def _inf_generator():\n",
    "    index = 0\n",
    "    while True:                       \n",
    "        x_data = x_test_data[index:index+BATCH_SIZE]       \n",
    "        index+=BATCH_SIZE\n",
    "        \n",
    "        upd_print(str(index) + ' Images')\n",
    "        x_data=np.squeeze(x_data).astype('float32')\n",
    "        yield x_data\n",
    "\n",
    "def _generator():\n",
    "    index = 0\n",
    "    while True:       \n",
    "        batch_input = []\n",
    "        batch_output = []        \n",
    "        x_data = x_train_data[index:index+BATCH_SIZE]\n",
    "        y_data = y_train_data[index:index+BATCH_SIZE]       \n",
    "        \n",
    "        index+=BATCH_SIZE\n",
    "        \n",
    "        if (index >= TOTAL_SIZE):\n",
    "            index = 0\n",
    "        \n",
    "        \n",
    "        x_data=np.squeeze(x_data)\n",
    "        y_data=np.squeeze(y_data)\n",
    "        \n",
    "        y_data=np.expand_dims(y_data,axis=3)       \n",
    "        \n",
    "        yield x_data, y_data\n",
    "        \n",
    "def _inf_input_fn(dataset):\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images = iterator.get_next()\n",
    "    return images\n",
    "\n",
    "def input_fn(is_training, dataset, batch_size, num_epochs=1):\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# Set up a RunConfig to only save checkpoints once per training cycle.\n",
    "run_config = tf.estimator.RunConfig().replace(session_config=config, save_checkpoints_steps=TOTAL_SIZE)\n",
    "def upd_print(str):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=deeplabv3_model_fn,\n",
    "    config=run_config,\n",
    "    model_dir='path/to/model/dir',\n",
    "    params = {\n",
    "        'output_stride': 8,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'base_architecture': 'resnet_v2_101',\n",
    "        'pre_trained_model': 'path/to/resnet/checkpoint.ckpt',\n",
    "        'batch_norm_decay': _BATCH_NORM_DECAY,\n",
    "        'num_classes': _NUM_CLASSES,\n",
    "        'tensorboard_images_max_outputs': 6,\n",
    "        'weight_decay': 2e-4,\n",
    "        'learning_rate_policy': 'poly',\n",
    "        'num_train': TOTAL_SIZE,\n",
    "        'initial_learning_rate': 7e-3,\n",
    "        'max_iter': 30000,\n",
    "        'end_learning_rate': 1e-6,\n",
    "        'power': _POWER,\n",
    "        'momentum': _MOMENTUM,\n",
    "        'freeze_batch_norm': False,\n",
    "        'initial_global_step': 0\n",
    "      })\n",
    "\n",
    "for _ in range(EPOCHS):\n",
    "    tensors_to_log = {\n",
    "    'learning_rate': 'learning_rate',\n",
    "    'cross_entropy': 'cross_entropy',\n",
    "    'train_px_accuracy': 'train_px_accuracy',\n",
    "    'train_mean_iou': 'train_mean_iou',\n",
    "    'train_auc' : 'train_auc'\n",
    "  }\n",
    "    x_train_data, y_train_data = importRandomBatch(TOTAL_SIZE,'train', SCALE_RATE)\n",
    "    x_train_data = x_train_data.astype('float16')\n",
    "    y_train_data = y_train_data.astype('uint8')\n",
    "\n",
    "    y_train_data=np.expand_dims(y_train_data,axis=3)\n",
    "\n",
    " \n",
    "    dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
    "                                     output_types=(tf.float32, tf.uint8),\n",
    "                                     output_shapes=(tf.TensorShape(IMG_SHAPE), tf.TensorShape([IMG_SHAPE[0],IMG_SHAPE[1],1])))   \n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=TOTAL_SIZE)\n",
    "    dataset = dataset.repeat().batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=10)\n",
    "    train_hooks = [logging_hook]\n",
    "    eval_hooks = None\n",
    "\n",
    "\n",
    "    tf.logging.info(\"Start training.\")\n",
    "    model.train(\n",
    "      input_fn=lambda: input_fn(True, dataset, BATCH_SIZE, EPOCHS_PER_EVAL),\n",
    "      hooks=train_hooks,\n",
    "      steps=TOTAL_SIZE + 5 \n",
    "    )\n",
    "\n",
    "    tf.logging.info(\"Epoch ended.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MINIMAL CODE TO PREDICT FROM ESTIMATOR SAVED MODEL\"\"\"\n",
    "\n",
    "from ImportUtil import *\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import predictor\n",
    "import time\n",
    "\n",
    "latest = '/path/to/exported/model'\n",
    "x_test = ImportImages('/path/to/image/folder')\n",
    "predict_fn = predictor.from_saved_model(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data=x_test.astype('float32')\n",
    "pred1=[]\n",
    "for i in range(500):\n",
    "    pred = predict_fn({'image':[x_test_data[i]]})\n",
    "    pred1.append(pred)        \n",
    "    upd_print(str(i))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
